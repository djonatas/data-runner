# Data-Runner

ğŸ¯ **Executor de consultas/processos parametrizado por JSON**

Data-Runner Ã© uma ferramenta CLI robusta para **orquestraÃ§Ã£o de pipelines de dados** que automatiza a execuÃ§Ã£o de consultas SQL, transformaÃ§Ãµes e carregamentos de dados entre diferentes fontes.

**O que o Data-Runner faz:**

- ğŸ”„ **Automatiza pipelines de dados** atravÃ©s de arquivos JSON de configuraÃ§Ã£o
- ğŸ—„ï¸ **Conecta mÃºltiplas fontes** (PostgreSQL, MySQL, SQL Server, Oracle, CSV, SQLite)
- ğŸ“Š **Executa consultas SQL** parametrizadas com variÃ¡veis dinÃ¢micas
- ğŸ—ï¸ **ConstrÃ³i data warehouses** locais usando DuckDB como repositÃ³rio central
- ğŸ”— **Gerencia dependÃªncias** entre jobs para execuÃ§Ã£o ordenada e paralela
- ğŸ“ˆ **Monitora execuÃ§Ãµes** com auditoria completa e histÃ³rico detalhado
- ğŸ¯ **Exporta resultados** para CSV com configuraÃ§Ãµes personalizÃ¡veis
- âš¡ **Executa em lote** jobs individuais, por tipo ou grupos configurados

**Casos de uso tÃ­picos:**

- MigraÃ§Ã£o de dados entre sistemas
- ETL/ELT automatizado para data warehouses
- ConsolidaÃ§Ã£o de dados de mÃºltiplas fontes
- RelatÃ³rios automatizados com exportaÃ§Ã£o
- ValidaÃ§Ã£o e batimento de dados
- Pipelines de dados para anÃ¡lise e BI

## ğŸš€ Quick Start

### InstalaÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# InstalaÃ§Ã£o automÃ¡tica
./install.sh

# Ou instalaÃ§Ã£o manual
python -m pip install -e .
```

### ConfiguraÃ§Ã£o Inicial

```bash
# Setup automÃ¡tico
./setup.sh

# Ou configuraÃ§Ã£o manual
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json
```

### Uso BÃ¡sico

```bash
# Listar jobs disponÃ­veis
data-runner list-jobs

# Executar um job
data-runner run --id meu_job

# Executar mÃºltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Ver histÃ³rico
data-runner history

# Ajuda
data-runner --help
```

## ğŸ“‹ Comandos CLI

### Listar Jobs

```bash
# Listar todos os jobs
data-runner list-jobs

# Listar grupos configurados
data-runner list-groups
```

### Executar Jobs

```bash
# Executar job Ãºnico
data-runner run --id meu_job

# Executar job com limite
data-runner run --id meu_job --limit 1000

# Executar job em modo dry-run
data-runner run --id meu_job --dry-run

# Executar mÃºltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Executar jobs por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group meu_grupo
```

### HistÃ³rico e InspeÃ§Ã£o

```bash
# Ver histÃ³rico de execuÃ§Ãµes
data-runner history

# Ver histÃ³rico de job especÃ­fico
data-runner history --query-id meu_job

# Inspecionar banco DuckDB
data-runner inspect

# Inspecionar tabela especÃ­fica
data-runner inspect --table minha_tabela
```

### Gerenciamento

```bash
# Remover tabela
data-runner drop-table --table tabela_antiga

# Remover tabela com confirmaÃ§Ã£o
data-runner drop-table --table tabela_antiga --confirm
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo connections.json

```json
{
  "defaultDuckDbPath": "./data/warehouse.duckdb",
  "connections": [
    {
      "name": "meu_postgres",
      "type": "postgres",
      "params": {
        "host": "${env:POSTGRES_HOST}",
        "port": 5432,
        "database": "${env:POSTGRES_DATABASE}",
        "user": "${env:POSTGRES_USER}",
        "password": "${env:POSTGRES_PASSWORD}",
        "schema": "public"
      }
    }
  ]
}
```

### Arquivo jobs.json

```json
{
  "variables": {
    "tenant_id": {
      "value": "12345",
      "type": "string",
      "description": "ID do tenant"
    }
  },
  "jobs": [
    {
      "queryId": "meu_job",
      "type": "carga",
      "connection": "meu_postgres",
      "sql": "SELECT * FROM usuarios WHERE tenant_id = '${var:tenant_id}'",
      "targetTable": "usuarios_importados",
      "dependencies": ["job_anterior"]
    }
  ],
  "job_groups": {
    "cargas_diarias": {
      "description": "Cargas diÃ¡rias de dados",
      "job_ids": ["job1", "job2", "job3"]
    }
  }
}
```

### Arquivo .env

```bash
# VariÃ¡veis de ambiente
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=meu_banco
POSTGRES_USER=meu_usuario
POSTGRES_PASSWORD=minha_senha
```

## ğŸ”§ Tipos de ConexÃ£o

### PostgreSQL

```json
{
  "name": "postgres_db",
  "type": "postgres",
  "params": {
    "host": "localhost",
    "port": 5432,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "public"
  }
}
```

### MySQL

```json
{
  "name": "mysql_db",
  "type": "mysql",
  "params": {
    "host": "localhost",
    "port": 3306,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "meu_schema"
  }
}
```

### SQL Server

```json
{
  "name": "mssql_db",
  "type": "mssql",
  "params": {
    "host": "localhost",
    "port": 1433,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "dbo"
  }
}
```

### Oracle

```json
{
  "name": "oracle_db",
  "type": "oracle",
  "params": {
    "host": "localhost",
    "port": 1521,
    "database": "XE",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### Oracle TNS Names

```json
{
  "name": "oracle_tns",
  "type": "oracle",
  "params": {
    "database": "ERP_PROD",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### CSV

```json
{
  "name": "csv_data",
  "type": "csv",
  "params": {
    "csv_file": "./data/arquivo.csv",
    "csv_separator": ",",
    "csv_encoding": "utf-8",
    "csv_has_header": true
  }
}
```

## ğŸ“Š Tipos de Job

### Carga (carga)

```json
{
  "queryId": "importar_usuarios",
  "type": "carga",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios WHERE ativo = true",
  "targetTable": "usuarios_ativos"
}
```

### Batimento (batimento)

```json
{
  "queryId": "validar_dados",
  "type": "batimento",
  "connection": "postgres_db",
  "sql": "SELECT COUNT(*) as total FROM usuarios_ativos",
  "targetTable": "contagem_usuarios"
}
```

### ValidaÃ§Ã£o (validation)

```json
{
  "queryId": "validar_dados_usuarios",
  "type": "validation",
  "main_query": "importar_usuarios",
  "validation_file": "user_data_validation.py",
  "dependencies": ["importar_usuarios"]
}
```

### Export CSV (export-csv)

```json
{
  "queryId": "exportar_relatorio",
  "type": "export-csv",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios_ativos ORDER BY nome",
  "csv_file": "relatorio_usuarios.csv",
  "csv_separator": ",",
  "csv_encoding": "utf-8",
  "csv_include_header": true
}
```

## ğŸ” Motor de ValidaÃ§Ã£o de Dados

O Data-Runner inclui um motor de validaÃ§Ã£o que permite executar validaÃ§Ãµes personalizadas em Python sobre os dados carregados.

### Como Funciona

1. **ConfiguraÃ§Ã£o**: Define um job do tipo `validation` no `jobs.json`
2. **Query Principal**: Especifica qual job (`main_query`) fornecerÃ¡ os dados
3. **Arquivo Python**: Cria um arquivo Python com a lÃ³gica de validaÃ§Ã£o
4. **ExecuÃ§Ã£o**: O motor carrega dinamicamente o arquivo e executa a validaÃ§Ã£o

### Tipos de ValidaÃ§Ã£o

#### ğŸ” ValidaÃ§Ã£o por Registro (Recomendado)

- **FunÃ§Ã£o**: `validate_record(record, context)`
- **ExecuÃ§Ã£o**: Uma vez para cada linha/registro dos dados
- **Uso**: ValidaÃ§Ãµes especÃ­ficas por registro, verificaÃ§Ãµes individuais
- **Vantagem**: Detalhamento por registro, identificaÃ§Ã£o precisa de problemas
- **Exemplo**: Validar email de cada usuÃ¡rio individualmente

#### ğŸ“Š ValidaÃ§Ã£o por Dataset (Tradicional)

- **FunÃ§Ã£o**: `validate(data, context)`
- **ExecuÃ§Ã£o**: Uma vez para todo o dataset
- **Uso**: ValidaÃ§Ãµes gerais, estatÃ­sticas do dataset
- **Vantagem**: VisÃ£o geral, validaÃ§Ãµes de integridade
- **Exemplo**: Verificar se hÃ¡ duplicatas no dataset completo

### Estrutura do Arquivo de ValidaÃ§Ã£o

#### ValidaÃ§Ã£o por Registro (Recomendado)

```python
# validations/minha_validacao.py
from app.validation_engine import ValidationResult
import pandas as pd

def validate_record(record: Dict[str, Any], context: Dict[str, Any] = None) -> ValidationResult:
    """
    FunÃ§Ã£o executada uma vez para cada registro

    Args:
        record: DicionÃ¡rio com os dados do registro (inclui _record_index)
        context: Contexto adicional (main_query_id, validation_query_id, etc.)

    Returns:
        ValidationResult com o resultado da validaÃ§Ã£o para este registro
    """

    record_index = record.get('_record_index', 'N/A')

    # Sua lÃ³gica de validaÃ§Ã£o para este registro especÃ­fico
    if 'id' not in record:
        return ValidationResult(
            success=False,
            message=f"Registro {record_index}: Campo 'id' obrigatÃ³rio",
            details={"record_index": record_index, "missing_field": "id"}
        )

    if not record.get('name'):
        return ValidationResult(
            success=False,
            message=f"Registro {record_index}: Campo 'name' obrigatÃ³rio",
            details={"record_index": record_index, "missing_field": "name"}
        )

    return ValidationResult(
        success=True,
        message=f"Registro {record_index} vÃ¡lido",
        details={"record_index": record_index}
    )

# FunÃ§Ã£o de validaÃ§Ã£o tradicional (opcional, para compatibilidade)
def validate(data: pd.DataFrame, context: Dict[str, Any] = None) -> ValidationResult:
    """
    ValidaÃ§Ã£o tradicional (executada uma vez para todo o dataset)
    """
    if data.empty:
        return ValidationResult(
            success=False,
            message="Nenhum dado encontrado",
            details={"row_count": 0}
        )

    return ValidationResult(
        success=True,
        message="ValidaÃ§Ã£o passou com sucesso",
        details={"row_count": len(data)}
    )
```

#### ValidaÃ§Ã£o Tradicional (Dataset Completo)

```python
# validations/validacao_tradicional.py
from app.validation_engine import ValidationResult
import pandas as pd

def validate(data: pd.DataFrame, context: Dict[str, Any] = None) -> ValidationResult:
    """
    FunÃ§Ã£o de validaÃ§Ã£o tradicional (executada uma vez para todo o dataset)

    Args:
        data: DataFrame com os dados a serem validados
        context: Contexto adicional (main_query_id, validation_query_id, etc.)

    Returns:
        ValidationResult com o resultado da validaÃ§Ã£o
    """

    # Sua lÃ³gica de validaÃ§Ã£o aqui
    if data.empty:
        return ValidationResult(
            success=False,
            message="Nenhum dado encontrado",
            details={"row_count": 0}
        )

    # Exemplo: verificar se hÃ¡ dados nulos
    null_count = data.isnull().sum().sum()

    if null_count > 0:
        return ValidationResult(
            success=False,
            message=f"Encontrados {null_count} valores nulos",
            details={"null_count": int(null_count)}
        )

    return ValidationResult(
        success=True,
        message="ValidaÃ§Ã£o passou com sucesso",
        details={"row_count": len(data)}
    )
```

### ParÃ¢metros de ValidaÃ§Ã£o

| ParÃ¢metro         | Tipo   | ObrigatÃ³rio | DescriÃ§Ã£o                                     |
| ----------------- | ------ | ----------- | --------------------------------------------- |
| `validation_file` | string | Sim         | Caminho do arquivo Python de validaÃ§Ã£o        |
| `main_query`      | string | Sim         | ID do job que fornece os dados para validaÃ§Ã£o |
| `connection`      | string | NÃ£o         | ConexÃ£o para contexto (opcional)              |
| `dependencies`    | array  | NÃ£o         | Lista de jobs que devem executar antes        |
| `output_table`    | string | NÃ£o         | Nome da tabela para salvar resultados         |
| `pkey_field`      | string | NÃ£o         | Campo chave primÃ¡ria para indexaÃ§Ã£o           |

### Exemplos PrÃ¡ticos

#### ValidaÃ§Ã£o por Registro de UsuÃ¡rios (Com Output)

```json
{
  "queryId": "validate_users_per_record",
  "type": "validation",
  "main_query": "load_users",
  "validation_file": "user_per_record_validation.py",
  "output_table": "user_validation_results",
  "pkey_field": "id",
  "dependencies": ["load_users"]
}
```

#### ValidaÃ§Ã£o por Registro (Sem Output)

```json
{
  "queryId": "validate_users_per_record_simple",
  "type": "validation",
  "main_query": "load_users",
  "validation_file": "user_per_record_validation.py",
  "dependencies": ["load_users"]
}
```

#### ValidaÃ§Ã£o Tradicional de Dataset

```json
{
  "queryId": "validate_sales_data",
  "type": "validation",
  "main_query": "load_sales_csv",
  "validation_file": "example_validation.py",
  "dependencies": ["load_sales_csv"]
}
```

#### ValidaÃ§Ã£o Individual de Registros

```json
{
  "queryId": "validate_records_individually",
  "type": "validation",
  "main_query": "load_products_csv",
  "validation_file": "per_record_validation.py",
  "dependencies": ["load_products_csv"]
}
```

### ExecuÃ§Ã£o de ValidaÃ§Ãµes

```bash
# Executar validaÃ§Ã£o individual
data-runner run --id validate_user_data

# Executar todas as validaÃ§Ãµes
data-runner run-group --type validation

# Executar grupo de validaÃ§Ãµes
data-runner run-group-config --group validations
```

### Barra de Progresso

Durante a execuÃ§Ã£o de validaÃ§Ãµes por registro, o sistema exibe uma barra de progresso em tempo real:

```
ğŸš€ Validando 100 registros â†’ user_validation_results
============================================================
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.0% (100/100) | Tempo: 3.2s | 31.3 reg/s
âœ… ValidaÃ§Ã£o concluÃ­da!
   ğŸ“Š Total processado: 100 registros
   âœ… Sucessos: 95 (95.0%)
   âŒ Erros: 5
   â±ï¸  Tempo total: 3.2s
   ğŸš€ Velocidade: 31.3 registros/segundo
   ğŸ’¾ Resultados salvos em: user_validation_results
============================================================
```

#### InformaÃ§Ãµes da Barra de Progresso

- **ğŸ“Š Porcentagem**: Progresso atual da validaÃ§Ã£o
- **ğŸ“ˆ Barra visual**: RepresentaÃ§Ã£o grÃ¡fica do progresso
- **ğŸ”¢ Contadores**: Registros processados vs. total
- **â±ï¸ Tempo decorrido**: Tempo desde o inÃ­cio
- **ğŸ¯ ETA**: Estimativa de tempo restante
- **ğŸš€ Velocidade**: Registros processados por segundo
- **âœ…/âŒ Resultados**: Contadores de sucessos e erros
- **ğŸ’¾ Output**: Tabela onde os resultados foram salvos

### Tabela de Output de ValidaÃ§Ã£o

Quando configurado com `output_table` e `pkey_field`, os resultados sÃ£o salvos em uma tabela estruturada:

#### Estrutura da Tabela

| Campo             | Tipo    | DescriÃ§Ã£o                                |
| ----------------- | ------- | ---------------------------------------- |
| `execution_count` | INTEGER | NÃºmero sequencial da execuÃ§Ã£o (PK)       |
| `pkey`            | VARCHAR | Chave primÃ¡ria do registro validado (PK) |
| `result`          | VARCHAR | Resultado: "success" ou "error"          |
| `message`         | TEXT    | Mensagem da validaÃ§Ã£o                    |
| `details`         | TEXT    | Detalhes em JSON                         |
| `input_data`      | TEXT    | Dados do registro em JSON                |
| `executed_at`     | VARCHAR | Timestamp da execuÃ§Ã£o                    |

#### BenefÃ­cios da Tabela de Output

- **ğŸ“Š HistÃ³rico completo**: Todas as validaÃ§Ãµes por registro
- **ğŸ” Rastreabilidade**: Identificar exatamente qual registro falhou
- **ğŸ“ˆ AnÃ¡lise temporal**: EvoluÃ§Ã£o da qualidade dos dados
- **ğŸ¯ CorreÃ§Ã£o direcionada**: Saber exatamente o que corrigir
- **ğŸ“‹ RelatÃ³rios**: Consultas SQL para anÃ¡lise de qualidade

### Resultados de ValidaÃ§Ã£o

Os resultados sÃ£o armazenados na tabela de auditoria e incluem:

#### Para ValidaÃ§Ã£o por Registro:

- **Status**: Sucesso/Falha geral da validaÃ§Ã£o
- **Mensagem**: Resumo dos resultados (ex: "150 de 200 registros vÃ¡lidos")
- **Detalhes**: EstatÃ­sticas detalhadas:
  - `validation_type`: "per_record"
  - `total_records`: NÃºmero total de registros
  - `successful_records`: Registros que passaram na validaÃ§Ã£o
  - `failed_records`: Registros que falharam
  - `success_rate`: Taxa de sucesso em percentual
  - `failed_records_details`: Detalhes dos primeiros 10 registros que falharam
  - `error_records_details`: Detalhes dos primeiros 10 registros com erro

#### Para ValidaÃ§Ã£o Tradicional:

- **Status**: Sucesso/Falha da validaÃ§Ã£o
- **Mensagem**: DescriÃ§Ã£o do resultado
- **Detalhes**: InformaÃ§Ãµes gerais sobre o dataset
- **Contexto**: Metadados sobre a execuÃ§Ã£o

### Exemplos de ValidaÃ§Ãµes IncluÃ­das

#### ValidaÃ§Ã£o Tradicional (Dataset):

- **`example_validation.py`**: ValidaÃ§Ã£o genÃ©rica com verificaÃ§Ãµes bÃ¡sicas
- **`user_data_validation.py`**: ValidaÃ§Ã£o especÃ­fica para dados de usuÃ¡rios (email, telefone, CPF)

#### ValidaÃ§Ã£o por Registro:

- **`per_record_validation.py`**: ValidaÃ§Ã£o genÃ©rica por registro (ID, nome, email, status)
- **`user_per_record_validation.py`**: ValidaÃ§Ã£o especÃ­fica de usuÃ¡rios por registro (email, telefone, CPF)

## ğŸ”„ Sistema de DependÃªncias

```json
{
  "jobs": [
    {
      "queryId": "carregar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados",
      "targetTable": "dados_carregados"
    },
    {
      "queryId": "processar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados_carregados WHERE status = 'ativo'",
      "targetTable": "dados_processados",
      "dependencies": ["carregar_dados"]
    }
  ]
}
```

## ğŸ“ Grupos de Jobs

```json
{
  "job_groups": {
    "pipeline_completo": {
      "description": "Pipeline completo de dados",
      "job_ids": ["carregar_dados", "processar_dados", "exportar_relatorio"]
    },
    "cargas_diarias": {
      "description": "Cargas diÃ¡rias",
      "job_ids": ["carregar_dados", "processar_dados"]
    }
  }
}
```

## ğŸ” VariÃ¡veis de Ambiente

### Uso em ConexÃµes

```json
{
  "params": {
    "host": "${env:POSTGRES_HOST}",
    "password": "${env:POSTGRES_PASSWORD}"
  }
}
```

### Uso em Jobs

```json
{
  "variables": {
    "tenant_id": {
      "value": "${env:TENANT_ID}",
      "type": "string"
    }
  }
}
```

## ğŸ› ï¸ Scripts de Ajuda

### install.sh

```bash
# InstalaÃ§Ã£o completa
./install.sh
```

### setup.sh

```bash
# Setup e configuraÃ§Ã£o
./setup.sh
```

### run.sh

```bash
# ExecuÃ§Ã£o interativa
./run.sh

# ExecuÃ§Ã£o direta
./run.sh run meu_job
./run.sh batch job1,job2
./run.sh group carga
./run.sh group-config meu_grupo
```

### test.sh

```bash
# Testes e validaÃ§Ã£o
./test.sh
```

## ğŸ“š Exemplos de Uso

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Listar jobs
data-runner list-jobs

# Executar job
data-runner run --id importar_usuarios

# Ver resultado
data-runner inspect --table usuarios_importados
```

### ExecuÃ§Ã£o com Limites

```bash
# Executar com limite de linhas
data-runner run --id importar_usuarios --limit 1000

# Executar em modo dry-run
data-runner run --id importar_usuarios --dry-run
```

### ExecuÃ§Ã£o em Lote

```bash
# Executar mÃºltiplos jobs
data-runner run-batch --ids importar_usuarios,processar_dados,exportar_relatorio

# Executar por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group pipeline_completo
```

### Monitoramento

```bash
# Ver histÃ³rico
data-runner history

# Ver histÃ³rico de job especÃ­fico
data-runner history --query-id importar_usuarios

# Ver detalhes de tabela
data-runner inspect --table usuarios_importados
```

## ğŸ” Troubleshooting

### Erro de ConexÃ£o

```bash
# Verificar configuraÃ§Ãµes
data-runner list-jobs

# Testar conexÃ£o
./test.sh config
```

### Erro de SQL

```bash
# Executar em modo dry-run
data-runner run --id problema_job --dry-run

# Verificar logs
python -m app run --id problema_job --verbose
```

### Problemas com DuckDB

```bash
# Inspecionar banco
data-runner inspect

# Ver tabelas
data-runner inspect --table audit_job_runs
```

---

## ğŸ‘¨â€ğŸ’» Para Desenvolvedores

### Tecnologias Utilizadas

- **Python 3.8+**: Linguagem principal
- **DuckDB**: Banco de dados local para persistÃªncia
- **pandas**: ManipulaÃ§Ã£o de dados
- **Click**: Interface CLI
- **psycopg2**: ConexÃ£o PostgreSQL
- **PyMySQL**: ConexÃ£o MySQL
- **pyodbc**: ConexÃ£o SQL Server
- **cx_Oracle**: ConexÃ£o Oracle
- **python-dotenv**: Carregamento de variÃ¡veis de ambiente

### Estrutura do Projeto

```
data-runner/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ cli.py              # Interface CLI
â”‚   â”œâ”€â”€ runner.py           # Orquestrador principal
â”‚   â”œâ”€â”€ connections.py      # Gerenciamento de conexÃµes
â”‚   â”œâ”€â”€ repository.py       # PersistÃªncia DuckDB
â”‚   â”œâ”€â”€ types.py           # Tipos e contratos
â”‚   â”œâ”€â”€ env_processor.py   # Processamento de variÃ¡veis de ambiente
â”‚   â”œâ”€â”€ variable_processor.py # Processamento de variÃ¡veis
â”‚   â”œâ”€â”€ dependency_manager.py # Gerenciamento de dependÃªncias
â”‚   â””â”€â”€ sql_utils.py       # UtilitÃ¡rios SQL
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ connections.json.example
â”‚   â””â”€â”€ jobs.json.example
â”œâ”€â”€ data/
â”‚   â””â”€â”€ warehouse.duckdb
â”œâ”€â”€ tests/
â””â”€â”€ scripts/
    â”œâ”€â”€ install.sh
    â”œâ”€â”€ setup.sh
    â”œâ”€â”€ run.sh
    â””â”€â”€ test.sh
```

### Fluxo Principal

1. **CLI** (`cli.py`) recebe comandos do usuÃ¡rio
2. **Runner** (`runner.py`) orquestra a execuÃ§Ã£o
3. **ConnectionFactory** (`connections.py`) cria conexÃµes com bancos
4. **Repository** (`repository.py`) persiste resultados no DuckDB
5. **Processadores** lidam com variÃ¡veis e dependÃªncias

### Classes Principais

- **`JobRunner`**: Orquestrador principal, gerencia execuÃ§Ã£o de jobs
- **`ConnectionFactory`**: Factory para criar conexÃµes com diferentes bancos
- **`DuckDBRepository`**: Gerencia persistÃªncia e auditoria no DuckDB
- **`EnvironmentVariableProcessor`**: Processa variÃ¡veis de ambiente
- **`VariableProcessor`**: Processa variÃ¡veis definidas em jobs.json
- **`DependencyManager`**: Gerencia dependÃªncias e ordenaÃ§Ã£o de jobs

### Setup Local

```bash
# Clone e setup
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# Ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# DependÃªncias
pip install -e .

# DependÃªncias opcionais
pip install -e ".[mysql,mssql,oracle]"

# ConfiguraÃ§Ã£o
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json

# Teste
python -m app.cli --help
```

### Desenvolvimento

```bash
# Executar testes
python -m pytest tests/

# Executar CLI
python -m app.cli list-jobs

# Debug
python -m app.cli run --id teste --verbose
```

---

## ğŸ“„ LicenÃ§a

MIT License - veja arquivo LICENSE para detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ Suporte

- **Issues**: [GitHub Issues](https://github.com/djonatas/data-runner/issues)
