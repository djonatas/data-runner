# Data-Runner

üéØ **Executor de consultas/processos parametrizado por JSON**

Data-Runner √© uma ferramenta CLI robusta para **orquestra√ß√£o de pipelines de dados** que automatiza a execu√ß√£o de consultas SQL, transforma√ß√µes e carregamentos de dados entre diferentes fontes. 

**O que o Data-Runner faz:**
- üîÑ **Automatiza pipelines de dados** atrav√©s de arquivos JSON de configura√ß√£o
- üóÑÔ∏è **Conecta m√∫ltiplas fontes** (PostgreSQL, MySQL, SQL Server, Oracle, CSV, SQLite)
- üìä **Executa consultas SQL** parametrizadas com vari√°veis din√¢micas
- üèóÔ∏è **Constr√≥i data warehouses** locais usando DuckDB como reposit√≥rio central
- üîó **Gerencia depend√™ncias** entre jobs para execu√ß√£o ordenada e paralela
- üìà **Monitora execu√ß√µes** com auditoria completa e hist√≥rico detalhado
- üéØ **Exporta resultados** para CSV com configura√ß√µes personaliz√°veis
- ‚ö° **Executa em lote** jobs individuais, por tipo ou grupos configurados

**Casos de uso t√≠picos:**
- Migra√ß√£o de dados entre sistemas
- ETL/ELT automatizado para data warehouses
- Consolida√ß√£o de dados de m√∫ltiplas fontes
- Relat√≥rios automatizados com exporta√ß√£o
- Valida√ß√£o e batimento de dados
- Pipelines de dados para an√°lise e BI

## üöÄ Quick Start

### Instala√ß√£o R√°pida

```bash
# Clone o reposit√≥rio
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# Instala√ß√£o autom√°tica
./install.sh

# Ou instala√ß√£o manual
python -m pip install -e .
```

### Configura√ß√£o Inicial

```bash
# Setup autom√°tico
./setup.sh

# Ou configura√ß√£o manual
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json
```

### Uso B√°sico

```bash
# Listar jobs dispon√≠veis
data-runner list-jobs

# Executar um job
data-runner run --id meu_job

# Executar m√∫ltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Ver hist√≥rico
data-runner history

# Ajuda
data-runner --help
```

## üìã Comandos CLI

### Listar Jobs

```bash
# Listar todos os jobs
data-runner list-jobs

# Listar grupos configurados
data-runner list-groups
```

### Executar Jobs

```bash
# Executar job √∫nico
data-runner run --id meu_job

# Executar job com limite
data-runner run --id meu_job --limit 1000

# Executar job em modo dry-run
data-runner run --id meu_job --dry-run

# Executar m√∫ltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Executar jobs por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group meu_grupo
```

### Hist√≥rico e Inspe√ß√£o

```bash
# Ver hist√≥rico de execu√ß√µes
data-runner history

# Ver hist√≥rico de job espec√≠fico
data-runner history --query-id meu_job

# Inspecionar banco DuckDB
data-runner inspect

# Inspecionar tabela espec√≠fica
data-runner inspect --table minha_tabela
```

### Gerenciamento

```bash
# Remover tabela
data-runner drop-table --table tabela_antiga

# Remover tabela com confirma√ß√£o
data-runner drop-table --table tabela_antiga --confirm
```

## ‚öôÔ∏è Configura√ß√£o

### Arquivo connections.json

```json
{
  "defaultDuckDbPath": "./data/warehouse.duckdb",
  "connections": [
    {
      "name": "meu_postgres",
      "type": "postgres",
      "params": {
        "host": "${env:POSTGRES_HOST}",
        "port": 5432,
        "database": "${env:POSTGRES_DATABASE}",
        "user": "${env:POSTGRES_USER}",
        "password": "${env:POSTGRES_PASSWORD}",
        "schema": "public"
      }
    }
  ]
}
```

### Arquivo jobs.json

```json
{
  "variables": {
    "tenant_id": {
      "value": "12345",
      "type": "string",
      "description": "ID do tenant"
    }
  },
  "jobs": [
    {
      "queryId": "meu_job",
      "type": "carga",
      "connection": "meu_postgres",
      "sql": "SELECT * FROM usuarios WHERE tenant_id = '${var:tenant_id}'",
      "targetTable": "usuarios_importados",
      "dependencies": ["job_anterior"]
    }
  ],
  "job_groups": {
    "cargas_diarias": {
      "description": "Cargas di√°rias de dados",
      "job_ids": ["job1", "job2", "job3"]
    }
  }
}
```

### Arquivo .env

```bash
# Vari√°veis de ambiente
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=meu_banco
POSTGRES_USER=meu_usuario
POSTGRES_PASSWORD=minha_senha
```

## üîß Tipos de Conex√£o

### PostgreSQL

```json
{
  "name": "postgres_db",
  "type": "postgres",
  "params": {
    "host": "localhost",
    "port": 5432,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "public"
  }
}
```

### MySQL

```json
{
  "name": "mysql_db",
  "type": "mysql",
  "params": {
    "host": "localhost",
    "port": 3306,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "meu_schema"
  }
}
```

### SQL Server

```json
{
  "name": "mssql_db",
  "type": "mssql",
  "params": {
    "host": "localhost",
    "port": 1433,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "dbo"
  }
}
```

### Oracle

```json
{
  "name": "oracle_db",
  "type": "oracle",
  "params": {
    "host": "localhost",
    "port": 1521,
    "database": "XE",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### Oracle TNS Names

```json
{
  "name": "oracle_tns",
  "type": "oracle",
  "params": {
    "database": "ERP_PROD",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### CSV

```json
{
  "name": "csv_data",
  "type": "csv",
  "params": {
    "csv_file": "./data/arquivo.csv",
    "csv_separator": ",",
    "csv_encoding": "utf-8",
    "csv_has_header": true
  }
}
```

## üìä Tipos de Job

### Carga (carga)

```json
{
  "queryId": "importar_usuarios",
  "type": "carga",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios WHERE ativo = true",
  "targetTable": "usuarios_ativos"
}
```

### Batimento (batimento)

```json
{
  "queryId": "validar_dados",
  "type": "batimento",
  "connection": "postgres_db",
  "sql": "SELECT COUNT(*) as total FROM usuarios_ativos",
  "targetTable": "contagem_usuarios"
}
```

### Export CSV (export-csv)

```json
{
  "queryId": "exportar_relatorio",
  "type": "export-csv",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios_ativos ORDER BY nome",
  "csv_file": "relatorio_usuarios.csv",
  "csv_separator": ",",
  "csv_encoding": "utf-8",
  "csv_include_header": true
}
```

## üîÑ Sistema de Depend√™ncias

```json
{
  "jobs": [
    {
      "queryId": "carregar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados",
      "targetTable": "dados_carregados"
    },
    {
      "queryId": "processar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados_carregados WHERE status = 'ativo'",
      "targetTable": "dados_processados",
      "dependencies": ["carregar_dados"]
    }
  ]
}
```

## üìÅ Grupos de Jobs

```json
{
  "job_groups": {
    "pipeline_completo": {
      "description": "Pipeline completo de dados",
      "job_ids": ["carregar_dados", "processar_dados", "exportar_relatorio"]
    },
    "cargas_diarias": {
      "description": "Cargas di√°rias",
      "job_ids": ["carregar_dados", "processar_dados"]
    }
  }
}
```

## üîê Vari√°veis de Ambiente

### Uso em Conex√µes

```json
{
  "params": {
    "host": "${env:POSTGRES_HOST}",
    "password": "${env:POSTGRES_PASSWORD}"
  }
}
```

### Uso em Jobs

```json
{
  "variables": {
    "tenant_id": {
      "value": "${env:TENANT_ID}",
      "type": "string"
    }
  }
}
```

## üõ†Ô∏è Scripts de Ajuda

### install.sh

```bash
# Instala√ß√£o completa
./install.sh
```

### setup.sh

```bash
# Setup e configura√ß√£o
./setup.sh
```

### run.sh

```bash
# Execu√ß√£o interativa
./run.sh

# Execu√ß√£o direta
./run.sh run meu_job
./run.sh batch job1,job2
./run.sh group carga
./run.sh group-config meu_grupo
```

### test.sh

```bash
# Testes e valida√ß√£o
./test.sh
```

## üìö Exemplos de Uso

### Execu√ß√£o B√°sica

```bash
# Listar jobs
data-runner list-jobs

# Executar job
data-runner run --id importar_usuarios

# Ver resultado
data-runner inspect --table usuarios_importados
```

### Execu√ß√£o com Limites

```bash
# Executar com limite de linhas
data-runner run --id importar_usuarios --limit 1000

# Executar em modo dry-run
data-runner run --id importar_usuarios --dry-run
```

### Execu√ß√£o em Lote

```bash
# Executar m√∫ltiplos jobs
data-runner run-batch --ids importar_usuarios,processar_dados,exportar_relatorio

# Executar por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group pipeline_completo
```

### Monitoramento

```bash
# Ver hist√≥rico
data-runner history

# Ver hist√≥rico de job espec√≠fico
data-runner history --query-id importar_usuarios

# Ver detalhes de tabela
data-runner inspect --table usuarios_importados
```

## üîç Troubleshooting

### Erro de Conex√£o

```bash
# Verificar configura√ß√µes
data-runner list-jobs

# Testar conex√£o
./test.sh config
```

### Erro de SQL

```bash
# Executar em modo dry-run
data-runner run --id problema_job --dry-run

# Verificar logs
python -m app run --id problema_job --verbose
```

### Problemas com DuckDB

```bash
# Inspecionar banco
data-runner inspect

# Ver tabelas
data-runner inspect --table audit_job_runs
```

---

## üë®‚Äçüíª Para Desenvolvedores

### Tecnologias Utilizadas

- **Python 3.8+**: Linguagem principal
- **DuckDB**: Banco de dados local para persist√™ncia
- **pandas**: Manipula√ß√£o de dados
- **Click**: Interface CLI
- **psycopg2**: Conex√£o PostgreSQL
- **PyMySQL**: Conex√£o MySQL
- **pyodbc**: Conex√£o SQL Server
- **cx_Oracle**: Conex√£o Oracle
- **python-dotenv**: Carregamento de vari√°veis de ambiente

### Estrutura do Projeto

```
data-runner/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py              # Interface CLI
‚îÇ   ‚îú‚îÄ‚îÄ runner.py           # Orquestrador principal
‚îÇ   ‚îú‚îÄ‚îÄ connections.py      # Gerenciamento de conex√µes
‚îÇ   ‚îú‚îÄ‚îÄ repository.py       # Persist√™ncia DuckDB
‚îÇ   ‚îú‚îÄ‚îÄ types.py           # Tipos e contratos
‚îÇ   ‚îú‚îÄ‚îÄ env_processor.py   # Processamento de vari√°veis de ambiente
‚îÇ   ‚îú‚îÄ‚îÄ variable_processor.py # Processamento de vari√°veis
‚îÇ   ‚îú‚îÄ‚îÄ dependency_manager.py # Gerenciamento de depend√™ncias
‚îÇ   ‚îî‚îÄ‚îÄ sql_utils.py       # Utilit√°rios SQL
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ connections.json.example
‚îÇ   ‚îî‚îÄ‚îÄ jobs.json.example
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ warehouse.duckdb
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ install.sh
    ‚îú‚îÄ‚îÄ setup.sh
    ‚îú‚îÄ‚îÄ run.sh
    ‚îî‚îÄ‚îÄ test.sh
```

### Fluxo Principal

1. **CLI** (`cli.py`) recebe comandos do usu√°rio
2. **Runner** (`runner.py`) orquestra a execu√ß√£o
3. **ConnectionFactory** (`connections.py`) cria conex√µes com bancos
4. **Repository** (`repository.py`) persiste resultados no DuckDB
5. **Processadores** lidam com vari√°veis e depend√™ncias

### Classes Principais

- **`JobRunner`**: Orquestrador principal, gerencia execu√ß√£o de jobs
- **`ConnectionFactory`**: Factory para criar conex√µes com diferentes bancos
- **`DuckDBRepository`**: Gerencia persist√™ncia e auditoria no DuckDB
- **`EnvironmentVariableProcessor`**: Processa vari√°veis de ambiente
- **`VariableProcessor`**: Processa vari√°veis definidas em jobs.json
- **`DependencyManager`**: Gerencia depend√™ncias e ordena√ß√£o de jobs

### Setup Local

```bash
# Clone e setup
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# Ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Depend√™ncias
pip install -e .

# Depend√™ncias opcionais
pip install -e ".[mysql,mssql,oracle]"

# Configura√ß√£o
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json

# Teste
python -m app.cli --help
```

### Desenvolvimento

```bash
# Executar testes
python -m pytest tests/

# Executar CLI
python -m app.cli list-jobs

# Debug
python -m app.cli run --id teste --verbose
```

---

## üìÑ Licen√ßa

MIT License - veja arquivo LICENSE para detalhes.

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìû Suporte

- **Issues**: [GitHub Issues](https://github.com/djonatas/data-runner/issues)
