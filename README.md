# Data-Runner

ğŸ¯ **Executor de consultas/processos parametrizado por JSON**

Data-Runner Ã© uma ferramenta CLI robusta para **orquestraÃ§Ã£o de pipelines de dados** que automatiza a execuÃ§Ã£o de consultas SQL, transformaÃ§Ãµes e carregamentos de dados entre diferentes fontes. 

**O que o Data-Runner faz:**
- ğŸ”„ **Automatiza pipelines de dados** atravÃ©s de arquivos JSON de configuraÃ§Ã£o
- ğŸ—„ï¸ **Conecta mÃºltiplas fontes** (PostgreSQL, MySQL, SQL Server, Oracle, CSV, SQLite)
- ğŸ“Š **Executa consultas SQL** parametrizadas com variÃ¡veis dinÃ¢micas
- ğŸ—ï¸ **ConstrÃ³i data warehouses** locais usando DuckDB como repositÃ³rio central
- ğŸ”— **Gerencia dependÃªncias** entre jobs para execuÃ§Ã£o ordenada e paralela
- ğŸ“ˆ **Monitora execuÃ§Ãµes** com auditoria completa e histÃ³rico detalhado
- ğŸ¯ **Exporta resultados** para CSV com configuraÃ§Ãµes personalizÃ¡veis
- âš¡ **Executa em lote** jobs individuais, por tipo ou grupos configurados

**Casos de uso tÃ­picos:**
- MigraÃ§Ã£o de dados entre sistemas
- ETL/ELT automatizado para data warehouses
- ConsolidaÃ§Ã£o de dados de mÃºltiplas fontes
- RelatÃ³rios automatizados com exportaÃ§Ã£o
- ValidaÃ§Ã£o e batimento de dados
- Pipelines de dados para anÃ¡lise e BI

## ğŸš€ Quick Start

### InstalaÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# InstalaÃ§Ã£o automÃ¡tica
./install.sh

# Ou instalaÃ§Ã£o manual
python -m pip install -e .
```

### ConfiguraÃ§Ã£o Inicial

```bash
# Setup automÃ¡tico
./setup.sh

# Ou configuraÃ§Ã£o manual
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json
```

### Uso BÃ¡sico

```bash
# Listar jobs disponÃ­veis
data-runner list-jobs

# Executar um job
data-runner run --id meu_job

# Executar mÃºltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Ver histÃ³rico
data-runner history

# Ajuda
data-runner --help
```

## ğŸ“‹ Comandos CLI

### Listar Jobs

```bash
# Listar todos os jobs
data-runner list-jobs

# Listar grupos configurados
data-runner list-groups
```

### Executar Jobs

```bash
# Executar job Ãºnico
data-runner run --id meu_job

# Executar job com limite
data-runner run --id meu_job --limit 1000

# Executar job em modo dry-run
data-runner run --id meu_job --dry-run

# Executar mÃºltiplos jobs
data-runner run-batch --ids job1,job2,job3

# Executar jobs por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group meu_grupo
```

### HistÃ³rico e InspeÃ§Ã£o

```bash
# Ver histÃ³rico de execuÃ§Ãµes
data-runner history

# Ver histÃ³rico de job especÃ­fico
data-runner history --query-id meu_job

# Inspecionar banco DuckDB
data-runner inspect

# Inspecionar tabela especÃ­fica
data-runner inspect --table minha_tabela
```

### Gerenciamento

```bash
# Remover tabela
data-runner drop-table --table tabela_antiga

# Remover tabela com confirmaÃ§Ã£o
data-runner drop-table --table tabela_antiga --confirm
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo connections.json

```json
{
  "defaultDuckDbPath": "./data/warehouse.duckdb",
  "connections": [
    {
      "name": "meu_postgres",
      "type": "postgres",
      "params": {
        "host": "${env:POSTGRES_HOST}",
        "port": 5432,
        "database": "${env:POSTGRES_DATABASE}",
        "user": "${env:POSTGRES_USER}",
        "password": "${env:POSTGRES_PASSWORD}",
        "schema": "public"
      }
    }
  ]
}
```

### Arquivo jobs.json

```json
{
  "variables": {
    "tenant_id": {
      "value": "12345",
      "type": "string",
      "description": "ID do tenant"
    }
  },
  "jobs": [
    {
      "queryId": "meu_job",
      "type": "carga",
      "connection": "meu_postgres",
      "sql": "SELECT * FROM usuarios WHERE tenant_id = '${var:tenant_id}'",
      "targetTable": "usuarios_importados",
      "dependencies": ["job_anterior"]
    }
  ],
  "job_groups": {
    "cargas_diarias": {
      "description": "Cargas diÃ¡rias de dados",
      "job_ids": ["job1", "job2", "job3"]
    }
  }
}
```

### Arquivo .env

```bash
# VariÃ¡veis de ambiente
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=meu_banco
POSTGRES_USER=meu_usuario
POSTGRES_PASSWORD=minha_senha
```

## ğŸ”§ Tipos de ConexÃ£o

### PostgreSQL

```json
{
  "name": "postgres_db",
  "type": "postgres",
  "params": {
    "host": "localhost",
    "port": 5432,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "public"
  }
}
```

### MySQL

```json
{
  "name": "mysql_db",
  "type": "mysql",
  "params": {
    "host": "localhost",
    "port": 3306,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "meu_schema"
  }
}
```

### SQL Server

```json
{
  "name": "mssql_db",
  "type": "mssql",
  "params": {
    "host": "localhost",
    "port": 1433,
    "database": "meu_banco",
    "user": "usuario",
    "password": "senha",
    "schema": "dbo"
  }
}
```

### Oracle

```json
{
  "name": "oracle_db",
  "type": "oracle",
  "params": {
    "host": "localhost",
    "port": 1521,
    "database": "XE",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### Oracle TNS Names

```json
{
  "name": "oracle_tns",
  "type": "oracle",
  "params": {
    "database": "ERP_PROD",
    "user": "usuario",
    "password": "senha",
    "schema": "HR"
  }
}
```

### CSV

```json
{
  "name": "csv_data",
  "type": "csv",
  "params": {
    "csv_file": "./data/arquivo.csv",
    "csv_separator": ",",
    "csv_encoding": "utf-8",
    "csv_has_header": true
  }
}
```

## ğŸ“Š Tipos de Job

### Carga (carga)

```json
{
  "queryId": "importar_usuarios",
  "type": "carga",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios WHERE ativo = true",
  "targetTable": "usuarios_ativos"
}
```

### Batimento (batimento)

```json
{
  "queryId": "validar_dados",
  "type": "batimento",
  "connection": "postgres_db",
  "sql": "SELECT COUNT(*) as total FROM usuarios_ativos",
  "targetTable": "contagem_usuarios"
}
```

### Export CSV (export-csv)

```json
{
  "queryId": "exportar_relatorio",
  "type": "export-csv",
  "connection": "postgres_db",
  "sql": "SELECT * FROM usuarios_ativos ORDER BY nome",
  "csv_file": "relatorio_usuarios.csv",
  "csv_separator": ",",
  "csv_encoding": "utf-8",
  "csv_include_header": true
}
```

## ğŸ”„ Sistema de DependÃªncias

```json
{
  "jobs": [
    {
      "queryId": "carregar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados",
      "targetTable": "dados_carregados"
    },
    {
      "queryId": "processar_dados",
      "type": "carga",
      "connection": "postgres_db",
      "sql": "SELECT * FROM dados_carregados WHERE status = 'ativo'",
      "targetTable": "dados_processados",
      "dependencies": ["carregar_dados"]
    }
  ]
}
```

## ğŸ“ Grupos de Jobs

```json
{
  "job_groups": {
    "pipeline_completo": {
      "description": "Pipeline completo de dados",
      "job_ids": ["carregar_dados", "processar_dados", "exportar_relatorio"]
    },
    "cargas_diarias": {
      "description": "Cargas diÃ¡rias",
      "job_ids": ["carregar_dados", "processar_dados"]
    }
  }
}
```

## ğŸ” VariÃ¡veis de Ambiente

### Uso em ConexÃµes

```json
{
  "params": {
    "host": "${env:POSTGRES_HOST}",
    "password": "${env:POSTGRES_PASSWORD}"
  }
}
```

### Uso em Jobs

```json
{
  "variables": {
    "tenant_id": {
      "value": "${env:TENANT_ID}",
      "type": "string"
    }
  }
}
```

## ğŸ› ï¸ Scripts de Ajuda

### install.sh

```bash
# InstalaÃ§Ã£o completa
./install.sh
```

### setup.sh

```bash
# Setup e configuraÃ§Ã£o
./setup.sh
```

### run.sh

```bash
# ExecuÃ§Ã£o interativa
./run.sh

# ExecuÃ§Ã£o direta
./run.sh run meu_job
./run.sh batch job1,job2
./run.sh group carga
./run.sh group-config meu_grupo
```

### test.sh

```bash
# Testes e validaÃ§Ã£o
./test.sh
```

## ğŸ“š Exemplos de Uso

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Listar jobs
data-runner list-jobs

# Executar job
data-runner run --id importar_usuarios

# Ver resultado
data-runner inspect --table usuarios_importados
```

### ExecuÃ§Ã£o com Limites

```bash
# Executar com limite de linhas
data-runner run --id importar_usuarios --limit 1000

# Executar em modo dry-run
data-runner run --id importar_usuarios --dry-run
```

### ExecuÃ§Ã£o em Lote

```bash
# Executar mÃºltiplos jobs
data-runner run-batch --ids importar_usuarios,processar_dados,exportar_relatorio

# Executar por tipo
data-runner run-group --type carga

# Executar grupo configurado
data-runner run-group-config --group pipeline_completo
```

### Monitoramento

```bash
# Ver histÃ³rico
data-runner history

# Ver histÃ³rico de job especÃ­fico
data-runner history --query-id importar_usuarios

# Ver detalhes de tabela
data-runner inspect --table usuarios_importados
```

## ğŸ” Troubleshooting

### Erro de ConexÃ£o

```bash
# Verificar configuraÃ§Ãµes
data-runner list-jobs

# Testar conexÃ£o
./test.sh config
```

### Erro de SQL

```bash
# Executar em modo dry-run
data-runner run --id problema_job --dry-run

# Verificar logs
python -m app run --id problema_job --verbose
```

### Problemas com DuckDB

```bash
# Inspecionar banco
data-runner inspect

# Ver tabelas
data-runner inspect --table audit_job_runs
```

---

## ğŸ‘¨â€ğŸ’» Para Desenvolvedores

### Tecnologias Utilizadas

- **Python 3.8+**: Linguagem principal
- **DuckDB**: Banco de dados local para persistÃªncia
- **pandas**: ManipulaÃ§Ã£o de dados
- **Click**: Interface CLI
- **psycopg2**: ConexÃ£o PostgreSQL
- **PyMySQL**: ConexÃ£o MySQL
- **pyodbc**: ConexÃ£o SQL Server
- **cx_Oracle**: ConexÃ£o Oracle
- **python-dotenv**: Carregamento de variÃ¡veis de ambiente

### Estrutura do Projeto

```
data-runner/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ cli.py              # Interface CLI
â”‚   â”œâ”€â”€ runner.py           # Orquestrador principal
â”‚   â”œâ”€â”€ connections.py      # Gerenciamento de conexÃµes
â”‚   â”œâ”€â”€ repository.py       # PersistÃªncia DuckDB
â”‚   â”œâ”€â”€ types.py           # Tipos e contratos
â”‚   â”œâ”€â”€ env_processor.py   # Processamento de variÃ¡veis de ambiente
â”‚   â”œâ”€â”€ variable_processor.py # Processamento de variÃ¡veis
â”‚   â”œâ”€â”€ dependency_manager.py # Gerenciamento de dependÃªncias
â”‚   â””â”€â”€ sql_utils.py       # UtilitÃ¡rios SQL
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ connections.json.example
â”‚   â””â”€â”€ jobs.json.example
â”œâ”€â”€ data/
â”‚   â””â”€â”€ warehouse.duckdb
â”œâ”€â”€ tests/
â””â”€â”€ scripts/
    â”œâ”€â”€ install.sh
    â”œâ”€â”€ setup.sh
    â”œâ”€â”€ run.sh
    â””â”€â”€ test.sh
```

### Fluxo Principal

1. **CLI** (`cli.py`) recebe comandos do usuÃ¡rio
2. **Runner** (`runner.py`) orquestra a execuÃ§Ã£o
3. **ConnectionFactory** (`connections.py`) cria conexÃµes com bancos
4. **Repository** (`repository.py`) persiste resultados no DuckDB
5. **Processadores** lidam com variÃ¡veis e dependÃªncias

### Classes Principais

- **`JobRunner`**: Orquestrador principal, gerencia execuÃ§Ã£o de jobs
- **`ConnectionFactory`**: Factory para criar conexÃµes com diferentes bancos
- **`DuckDBRepository`**: Gerencia persistÃªncia e auditoria no DuckDB
- **`EnvironmentVariableProcessor`**: Processa variÃ¡veis de ambiente
- **`VariableProcessor`**: Processa variÃ¡veis definidas em jobs.json
- **`DependencyManager`**: Gerencia dependÃªncias e ordenaÃ§Ã£o de jobs

### Setup Local

```bash
# Clone e setup
git clone https://github.com/djonatas/data-runner.git
cd data-runner

# Ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# DependÃªncias
pip install -e .

# DependÃªncias opcionais
pip install -e ".[mysql,mssql,oracle]"

# ConfiguraÃ§Ã£o
cp config/connections.json.example config/connections.json
cp config/jobs.json.example config/jobs.json

# Teste
python -m app.cli --help
```

### Desenvolvimento

```bash
# Executar testes
python -m pytest tests/

# Executar CLI
python -m app.cli list-jobs

# Debug
python -m app.cli run --id teste --verbose
```

---

## ğŸ“„ LicenÃ§a

MIT License - veja arquivo LICENSE para detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ Suporte

- **Issues**: [GitHub Issues](https://github.com/djonatas/data-runner/issues)
